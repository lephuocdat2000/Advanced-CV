{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled135.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/Advanced-CV/blob/main/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15HH5w-wEum2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e3bba7-e439-45bf-bde0-54d3aa55b43b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktm_bpe8dD0O"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import cv2\n",
        "import timeit\n",
        "import itertools "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUWov3rwdJlU"
      },
      "source": [
        "Compile darknet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29XI6D99pD2-"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/darknet\n",
        "!rm darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5v96Y08dVTr"
      },
      "source": [
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvYEW_jEdRL9"
      },
      "source": [
        "def load_network_1(config_file, data_file, weights, batch_size=1):\n",
        "    \"\"\"\n",
        "    load model description and weights from config files\n",
        "    args:\n",
        "        config_file (str): path to .cfg model file\n",
        "        data_file (str): path to .data model file\n",
        "        weights (str): path to weights\n",
        "    returns:\n",
        "        network: trained model\n",
        "        class_names\n",
        "        class_colors\n",
        "    \"\"\"\n",
        "    network = load_net_custom(\n",
        "        config_file.encode(\"ascii\"),\n",
        "        weights.encode(\"ascii\"), 0, batch_size)\n",
        "    metadata = load_meta(data_file.encode(\"ascii\"))\n",
        "    class_names = [metadata.names[i].decode(\"ascii\") for i in range(1)]\n",
        "    colors = class_colors(class_names)\n",
        "    return network, class_names, colors\n",
        "\n",
        "def darknet_helper(img, width, height):\n",
        "  darknet_image = make_image(width, height, 3)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img_resized = cv2.resize(img_rgb, (width, height),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # get image ratios to convert bounding boxes to proper size\n",
        "  img_height, img_width, _ = img.shape\n",
        "  width_ratio = img_width/width\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # run model on darknet style image to get detections\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  boxes = np.array([bbox2points(bbox) for _,_,bbox in detections])\n",
        "  boxes = boxes * [width_ratio, height_ratio, width_ratio, height_ratio]\n",
        "  return boxes\n",
        "\n",
        "def MatrixCreation(A,B,C,D):\n",
        "    width = int(max(np.sqrt((B[1]-A[1])**2+(B[0]-A[0])**2),np.sqrt((D[1]-C[1])**2+(D[0]-C[0])**2)))\n",
        "    height = int(max(np.sqrt((C[1]-A[1])**2+(C[0]-A[0])**2),np.sqrt((D[1]-B[1])**2+(D[0]-B[0])**2)))\n",
        "    inputs = np.float32([A,B,C,D])\n",
        "    outputs = np.float32([[0,0],\n",
        "                      [width-1,0],\n",
        "                      [0,height-1],\n",
        "                      [width-1,height-1]])\n",
        "    M = cv2.getPerspectiveTransform(inputs,outputs)\n",
        "    return M\n",
        "\n",
        "def Points_Transformation(boxes):\n",
        "    x_ = boxes[:,0]+(boxes[:,2]-boxes[:,0]) / 2\n",
        "    # y_ = boxes[:,1]+(boxes[:,3]-boxes[:,1]) / 2\n",
        "    y_ = boxes[:,3]\n",
        "    x_ = np.expand_dims(x_,axis = 1)\n",
        "    y_ = np.expand_dims(y_,axis = 1) \n",
        "    # centroids = np.uint32(np.concatenate((x_,y_),axis=1))\n",
        "    centroids = np.concatenate((x_,y_),axis=1)\n",
        "    #list_point_to_detect = np.float32(centroids).reshape(-1,1,2)\n",
        "    list_point_to_detect = centroids.reshape(-1,1,2)\n",
        "    transformed_points = cv2.perspectiveTransform(list_point_to_detect, M)\n",
        "    transformed_points = transformed_points.reshape(transformed_points.shape[0],transformed_points.shape[2])\n",
        "    return transformed_points\n",
        "\n",
        "def DrawnRectangel(boxes,image,point,color):\n",
        "    # xmin,ymin,xmax,ymax = int(boxes[point][0]),int(boxes[point][1]),int(boxes[point][2]),int(boxes[point][3])\n",
        "    xmin,ymin,xmax,ymax = boxes[point][:].astype(int)\n",
        "    cv2.rectangle(image,(int(xmin),int(ymin)),(int(xmax),int(ymax)),color,2)  \n",
        "\n",
        "def get_birds_eye_view_image(transformed_points,green_box,red_box,eye_view_height,eye_view_width):\n",
        "    blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width,eye_view_height))\n",
        "    cv2.putText(blank_image, str(len(red_box)), (120,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "    cv2.putText(blank_image, str(len(green_box)), (520,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "    for point in green_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,255,0),-1)\n",
        "    for point in red_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,0,255),-1)\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width//2,eye_view_height))\n",
        "    return blank_image\n",
        "     \n",
        "def video_processing(video_path,real_width,real_height,pixel_width,pixel_height):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if (cap.isOpened()==False): \n",
        "        print('Error opening video stream or file')\n",
        "    else: \n",
        "      blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "      blank_image = cv2.resize(blank_image,(960,540))\n",
        "      fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "      out = cv2.VideoWriter('output.avi',fourcc, 20, (1440,540))\n",
        "      while (True):\n",
        "          ret, frame = cap.read()\n",
        "          if ret==True:\n",
        "            alter_blank_image = blank_image.copy()\n",
        "            boxes = darknet_helper(frame,width,height)  \n",
        "            #boxes= boxes[~np.all(boxes== 0, axis=1)]    \n",
        "            transformed_points = Points_Transformation(boxes)\n",
        "            if len(boxes) > 1:\n",
        "                image_rect = frame.copy()\n",
        "                list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "                x_y_ = []\n",
        "                for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "                     if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "                         index_pt1 = list_indexes[i][0]\n",
        "                         index_pt2 = list_indexes[i][1]\n",
        "                     #change color top view\n",
        "                         cv2.circle(alter_blank_image,tuple(transformed_points[index_pt1].astype(int)),20,(0,0,255),-1)\n",
        "                         cv2.circle(alter_blank_image,tuple(transformed_points[index_pt2].astype(int)),20,(0,0,255),-1)\n",
        "                     #change color original frame\n",
        "                         DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "                         DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "                         x_y_.append(index_pt1)\n",
        "                         x_y_.append(index_pt2)\n",
        "                #select points to draw green box and green circle \n",
        "                diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "                for i in diff:\n",
        "                   DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "                   cv2.circle(alter_blank_image,tuple(transformed_points[i].astype(int)),20,(0,255,0),-1)\n",
        "            elif len(boxes)==1: \n",
        "                 image_rect = frame.copy()\n",
        "                 DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "                 cv2.circle(alter_blank_image,tuple(transformed_points[0].astype(int)),20,(0,255,0),-1)\n",
        "            else: image_rect = frame.copy()\n",
        "            alter_blank_image = cv2.resize(alter_blank_image,(alter_blank_image.shape[1]//2,alter_blank_image.shape[0]))\n",
        "            combined_image = np.concatenate((alter_blank_image,image_rect),axis=1)\n",
        "            out.write(combined_image)\n",
        "            if cv2.waitKey(1)==ord('q'): break\n",
        "          else: break \n",
        "    out.release()\n",
        "    return\n",
        "def show_webcam(mirror=False):\n",
        "    vid = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "       ret,frame = vid.read()\n",
        "       plt.imshow('frame',frame)\n",
        "       if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "    vid.release()\n",
        "    cv2.destroyAllWindows() \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFDkRImI1K6G"
      },
      "source": [
        "from darknet import *\n",
        "#608X608\n",
        "# load in our YOLOv4 architecture network\n",
        "network, class_names, class_colors = load_network_1(\"cfg/yolov4.cfg\", \"cfg/coco.data\", \"yolov4.weights\")\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5pNg4qNisN4"
      },
      "source": [
        "# Get transformation matrix\n",
        "A = [390,220]\n",
        "B = [840,220]\n",
        "C = [10,450]\n",
        "D = [900,450]\n",
        "distance_minimum = 2.0\n",
        "real_width,real_height = 7.5,8.0\n",
        "pixel_width,pixel_height = B[0] - A[0], C[1]-A[1]\n",
        "M = MatrixCreation(A,B,C,D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ75AYJH9BCf"
      },
      "source": [
        "Test trên ảnh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-xXuR79ebEw"
      },
      "source": [
        "image = cv2.imread(\"/content/drive/MyDrive/Advanced-CV/193593992_323953159303430_8126787994321005785_n.png\")\n",
        "boxes = darknet_helper(image, width, height)\n",
        "transformed_points = Points_Transformation(boxes)\n",
        "if len(boxes) > 1:\n",
        "    image_rect = image.copy()\n",
        "    list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "    x_y_ = []\n",
        "    for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "      if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "      #change color top view\n",
        "         index_pt1 = list_indexes[i][0]\n",
        "         index_pt2 = list_indexes[i][1]\n",
        "      #change color original frame\n",
        "         DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "         DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "         x_y_.append(index_pt1)\n",
        "         x_y_.append(index_pt2)\n",
        "         diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "         for i in diff: DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "elif len(boxes)==1: \n",
        "    image_rect = image.copy()\n",
        "    DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "else: image_rect = image.copy()\n",
        "birds_eye_view_image = get_birds_eye_view_image(transformed_points,diff,x_y_,image.shape[0],image.shape[1])\n",
        "combined_image = np.concatenate((birds_eye_view_image,image_rect), axis=1)\n",
        "plt.imshow(cv2.cvtColor(combined_image,cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_1ogdcR9DRC"
      },
      "source": [
        "Test video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS-ljJ56kxyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de37a394-422c-4587-c4fd-d2f95dc10c69"
      },
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "A = [250,130]\n",
        "B = [750,130]\n",
        "C = [10,310]\n",
        "D = [870,310]\n",
        "pixel_width,pixel_height = B[0] - A[0], C[1]-A[1]\n",
        "M = MatrixCreation(A,B,C,D)\n",
        "real_width,real_height = 7.5,8.0\n",
        "distance_minimum = 2.0\n",
        "video_path='/content/drive/MyDrive/Advanced-CV/People2_Trim.mp4'\n",
        "video_processing(video_path,real_width,real_height,pixel_width,pixel_height)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhimc6Sht5Uu"
      },
      "source": [
        "Test trên ảnh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QWvQAHvxGxJ"
      },
      "source": [
        "4 points image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui_Cxi1Esvft"
      },
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Advanced-CV/193593992_323953159303430_8126787994321005785_n.png')\n",
        "image = cv2.resize(image,(1024,768))\n",
        "cv2.circle(image,(390,320),10,(0,0,255),-1)\n",
        "cv2.circle(image,(840,320),10,(0,0,255),-1)\n",
        "cv2.circle(image,(200,750),10,(0,0,255),-1)\n",
        "cv2.circle(image,(1000,750),10,(0,0,255),-1)\n",
        "plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7638DkGxJ9q"
      },
      "source": [
        "4 points video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1Ags5Us8wu"
      },
      "source": [
        "A = [250,130]\n",
        "B = [750,130]\n",
        "C = [10,310]\n",
        "D = [870,310]\n",
        "pixel_widtd,pixel_height = B[0] - A[0], C[1]-A[1]\n",
        "M = MatrixCreation(A,B,C,D)\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Advanced-CV/People2_Trim.mp4')\n",
        "if (cap.isOpened()==False):\n",
        "    print('Error opening video stream or file')\n",
        "else: \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    while (True):\n",
        "       ret, frame = cap.read()\n",
        "       if ret==True:\n",
        "           out = cv2.VideoWriter('output.avi',fourcc, 24,(frame.shape[1],frame.shape[0]))\n",
        "           cv2.circle(frame,tuple(A),10,(0,0,255),-1)\n",
        "           cv2.circle(frame,tuple(B),10,(0,0,255),-1)\n",
        "           cv2.circle(frame,tuple(C),10,(0,0,255),-1)\n",
        "           cv2.circle(frame,tuple(D),10,(0,0,255),-1)\n",
        "           plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
        "           frame = cv2.warpPerspective(frame,M,(frame.shape[1],frame.shape[0]))\n",
        "           break\n",
        "           if cv2.waitKey(1)==ord('q'): break\n",
        "           out.write(frame)\n",
        "       else: break\n",
        "    out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
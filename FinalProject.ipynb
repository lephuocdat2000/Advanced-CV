{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled135.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMab3dVdz4nMxpPXgE/b4S4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/Advanced-CV/blob/main/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15HH5w-wEum2",
        "outputId": "a3a5d806-8678-4d8d-92e4-1c17dcb76fa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN6CmvXlAoSi",
        "outputId": "9e77f1b8-a841-4a11-8baa-edeab3bbf7f3"
      },
      "source": [
        "pip install tf2_yolov4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf2_yolov4\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/61/24a0aed949afc7715b767160abc241c7cd9e7ae9c34e4f8b42c1d6924e63/tf2_yolov4-0.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from tf2_yolov4) (1.19.5)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.7/dist-packages (from tf2_yolov4) (8.0.0)\n",
            "Collecting tensorflow-addons>=0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.9.1->tf2_yolov4) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, tf2-yolov4\n",
            "Successfully installed tensorflow-addons-0.13.0 tf2-yolov4-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81788R5HANC4"
      },
      "source": [
        "import tensorflow as tf\n",
        "#from tensorflow.python.keras.engine import training\n",
        "from tf2_yolov4.anchors import YOLOV4_ANCHORS\n",
        "from tf2_yolov4.model import YOLOv4\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import cv2\n",
        "import timeit\n",
        "\n",
        "WIDTH,HEIGHT=(1024,768)\n",
        "\n",
        "model = YOLOv4(\n",
        "        input_shape=(HEIGHT,WIDTH,3),\n",
        "        anchors= YOLOV4_ANCHORS,\n",
        "        num_classes= 80,\n",
        "        training=False,\n",
        "        yolo_max_boxes=50,\n",
        "        yolo_iou_threshold=0.5,\n",
        "        yolo_score_threshold=0.5,    \n",
        ")\n",
        "CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',\n",
        "    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',\n",
        "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
        "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
        "    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
        "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
        "    'bed', 'dining table', 'toilet', 'tv', 'laptop',  'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "model.load_weights('/content/drive/MyDrive/Pretrained/yolov4.h5')\n",
        "\n",
        "def images_processing(model,image,HEIGHT,WIDTH):\n",
        "    image=tf.convert_to_tensor(image,dtype=tf.float32)\n",
        "    #image = tf.io.decode_image(image)   #convert input -> tensor\n",
        "    image = tf.image.resize(image,(HEIGHT,WIDTH)) \n",
        "    images = tf.expand_dims(image,axis=0) / 255 # shape=(batch,(image.shape)) \n",
        "    boxes, scores, classes, detections = model.predict(images)\n",
        "    human_index = np.where(classes[0]==0)\n",
        "    boxes = np.array(itemgetter(*human_index)(boxes[0]))* [WIDTH, HEIGHT, WIDTH, HEIGHT]\n",
        "    scores = np.array(itemgetter(*human_index)(scores[0]))\n",
        "    classes = np.array(itemgetter(*human_index)(classes[0])).astype(int)\n",
        "    return boxes,scores,classes,detections\n",
        "def video_processing(model,video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if (cap.isOpened()==False): \n",
        "        print('Error opening video stream or file')\n",
        "        return \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter('output.avi',fourcc, 20, (768,1024))\n",
        "    #start = timeit.default_timer()\n",
        "    #start_video=0\n",
        "    while (True):\n",
        "        #start_video+=1\n",
        "        ret, frame = cap.read()\n",
        "        if ret==True:\n",
        "           frame=cv2.resize(frame,(768,1024))\n",
        "           #stop = timeit.default_timer()\n",
        "           #if (start_video==1) or (stop-start>=2.0):\n",
        "           boxes,scores,classes,detections = images_processing(model,frame,768,1024)\n",
        "           detections = len(classes)\n",
        "           if detections > 0:\n",
        "                  image_rect = frame.copy()\n",
        "                  for (xmin,ymin,xmax,ymax) in boxes:\n",
        "                      cv2.rectangle(image_rect,(int(xmin),int(ymin)),(int(xmax),int(ymax)),(0,255,0),2)         \n",
        "                  out.write(image_rect) \n",
        "              #start = timeit.default_timer()\n",
        "           else: out.write(frame)\n",
        "           if cv2.waitKey(1)==ord('q'): break\n",
        "        else: break \n",
        "    out.release()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PaAOjB5eFiL"
      },
      "source": [
        "#image_path= 'C:/tai lieu hoc tap/NhapmonCV/advanced_cv/test1.jpg'\n",
        "#image=cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
        "video_path='/content/video1.webm'\n",
        "#images_processing(model,image,HEIGHT,WIDTH)\n",
        "video_processing(model,video_path)"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}